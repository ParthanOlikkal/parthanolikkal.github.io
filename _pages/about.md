---
title: ""
layout: single
permalink: /
author_profile: true
classes: wide
sidebar:
  nav: false
---

<h2>Biography</h2>
<div style="font-size:0.9em;">
I am a Ph.D. Candidate at the <a href="https://umbc.edu/" target="_blank"><strong>University of Maryland Baltimore County</strong></a>, advised by <a href="https://www.csee.umbc.edu/ramana-vinjamuri/" target="_blank">Dr. Ramana Vinjamuri</a>. My research lies at the intersection of **Brain-Computer Interfaces, Reinforcement Learning and Robotics**. I build real-time adaptive pipelines for motor intent decoding using EEG and EMG signals, with applications in assistive technologies, rehabilitation, and neuroadaptive gaming.

Before joining UMBC, I worked on gesture decoding systems for prosthetics and interactive virtual environments. My work emphasizes synergy-driven analysis, multimodal control, and human-in-the-loop reinforcement learning.

üìÑ Download my [**CV**](/assets/docs/Parthan_CV.pdf)
</div>

<hr>

<div style="display: flex; flex-wrap: wrap; gap: 2rem; align-items: flex-start; justify-content: space-between; font-size:0.9em">

  <div style="flex: 1; min-width: 250px;">
    <h3>Interests</h3>
    <ul>
      <li>Brain-Computer Interfaces</li>
      <li>Reinforcement Learning</li>
      <li>EMG and EEG-based motor decoding</li>
      <li>Human-Robot Interaction</li>
      <li>Motion & Synergy Analysis</li>
    </ul>
  </div>

<div style="flex: 1; min-width: 250px;">
  <h3>Education</h3>
  <ul>
    <li>üéì <strong>Ph.D. in Computer Science</strong> (Present)<br>
        <span style="font-size: 0.8em;">
        University of Maryland, Baltimore County
        </span></li>
    <li>üéì <strong>M.S. in Computer Science</strong>, 2021<br>
        <span style="font-size: 0.8em;">
        University of Maryland, Baltimore County
        </span></li>
    <li>üéì <strong>B.Tech in Computer Science</strong>, 2017<br>
        <span style="font-size:0.8em;">
        Cochin University of Science and Technology
        </span></li>
  </ul>
</div>

</div>

---

<h2 id="publications">Publications</h2>

<a href="/publication/olikkal2024robio" style="text-decoration: none; color: inherit;" target="_blank">
<div style="display: flex; flex-wrap: wrap; gap: 2rem; align-items: flex-start; margin-bottom: 2rem;
            border: 1px solid #e0e0e0; border-radius: 8px; padding: 1.5rem; background: #fafafa; font-size: 0.9em;
            transition: transform 0.2s ease-in-out; box-shadow: 0 0 0 transparent;"
     onmouseover="this.style.transform='scale(1.015)'; this.style.boxShadow='0 8px 20px rgba(0,0,0,0.1)'"
     onmouseout="this.style.transform='scale(1)'; this.style.boxShadow='0 0 0 transparent'">

  <!-- LEFT: Image -->
  <div style="flex: 1 1 300px; min-width: 250px;">
    <img src="/assets/images/EEG_EMG_Robot.png" alt="Paper teaser" style="width: 100%; border-radius: 8px;">
        <p style="color: #555; font-style:italic; font-size:0.75em">
    Key Areas - Multimodal Signal Processing, Deep Learning (Transformers), Robotics & Human-Robot Interaction
    </p>
  </div>

  <!-- RIGHT: Text -->
  <div style="flex: 2 1 400px; min-width: 250px; font-size:0.8em">

    <p style="font-size: 0.9em; color: #555;">
      <strong>Parthan Olikkal</strong>, Branesh M. Pillai, Jackrit Suthakorn, Habib Ali, Ramana Vinjamuri  
      <br>2024 ‚Äì <em>IEEE Robotics and Biomimetics</em>
    </p>

    <h3 style="margin-top: 0;">A Hybrid EEG-EMG Framework for Humanoid Control using Deep Learning Transformers</h3>

    <p style="color: #555;font-style:0.8em">
      This study presents a Transformer-based deep learning approach that integrates EEG and EMG signals to enhance upper limb motor control for rehabilitation. Ten able-bodied subjects performed center-out tasks of varying complexity, with simultaneous EEG, EMG, and 2D kinematic data collection. The fused signals enabled the model to achieve 87.27% accuracy across all levels and control a humanoid robot to replicate movements. The results demonstrate the effectiveness of EEG-EMG fusion in improving precision and performance in BCI-driven assistive and neurorehabilitation technologies.
    </p>



<!-- Button Group -->
<div class="btn-links" style="margin-top: 1rem; font-size:1em;">
  <button onclick="openBibModal('/assets/bib/Olikkal_2024_ROBIO.bib', 'bibModal-robio2024')" 
          class="btn btn-outline-primary btn-page-header btn-sm">Cite</button>
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://doi.org/10.1109/ROBIO64047.2024.10907308" target="_blank" rel="noopener">DOI</a>
</div>

<!-- Modal -->
<div id="bibModal-robio2024" style="display:none; position: fixed; z-index: 9999; left: 0; top: 0; width: 100%; height: 100%;
     background-color: rgba(0,0,0,0.5); text-align: center;">
  <div style="background: #fff; margin: 10% auto; padding: 20px; border-radius: 10px; width: 90%; max-width: 700px; position: relative;">
    <h3>BibTeX Citation</h3>
    <textarea id="bibtexText-robio2024" readonly style="width: 100%; height: 300px; padding: 10px; font-family: monospace;
              border: 1px solid #ccc; border-radius: 6px; color: black; background-color: white">Loading...</textarea>
    <div style="margin-top: 1rem;">
      <button onclick="copyBibTex('bibtexText-robio2024')" class="btn btn-sm" style="margin-right: 10px;">üìã Copy</button>
      <a href="/assets/bib/Olikkal_2024_ROBIO.bib" download class="btn btn-sm" style="margin-right: 10px;">‚¨áÔ∏è Download</a>
      <button onclick="document.getElementById('bibModal-robio2024').style.display='none'" class="btn btn-sm">‚ùå Close</button>
    </div>
  </div>
</div>

  </div>
</div>


<a href="/publication/olikkal2024robio" style="text-decoration: none; color: inherit;" target="_blank">
<div style="display: flex; flex-wrap: wrap; gap: 2rem; align-items: flex-start; margin-bottom: 2rem;
            border: 1px solid #e0e0e0; border-radius: 8px; padding: 1.5rem; background: #fafafa; font-size: 0.9em;
            transition: transform 0.2s ease-in-out; box-shadow: 0 0 0 transparent;"
     onmouseover="this.style.transform='scale(1.015)'; this.style.boxShadow='0 8px 20px rgba(0,0,0,0.1)'"
     onmouseout="this.style.transform='scale(1)'; this.style.boxShadow='0 0 0 transparent'">

  <!-- LEFT: Image -->
  <div style="flex: 1 1 300px; min-width: 250px;">
    <img src="/assets/images/Biomimetic_Robot.jpg" alt="Paper teaser" style="width: 100%; border-radius: 8px;">
    <p style="color: #555; font-style:italic; font-size:0.75em">
    Key Areas - Computer Vision, Kinematic Synergy, Robotics & Human-Robot Interaction
    </p>
  </div>

  <!-- RIGHT: Text -->
  <div style="flex: 2 1 400px; min-width: 250px; font-size:0.8em">

    <p style="font-size: 0.9em; color: #555;">
      <strong>Parthan Olikkal</strong>, Dingyi Pei, Bharat Kashyap Karri, Ashwin Satyanarayana, Nayan M. Kakoty, Ramana Vinjamuri  
      <br>2024 ‚Äì <em>Frontiers Human Neuroscience</em>
    </p>

    <h3 style="margin-top: 0;">Biomimetic learning of hand gestures in a humanoid robot</h3>

    <p style="color: #555;font-style:0.8em">
      This study explores the use of kinematic synergies‚Äîlow-dimensional movement patterns‚Äîfor real-time humanoid robot hand gesture replication. Using MediaPipe and a single RGB camera, 33 static hand gestures were recorded and reduced to joint angular velocities. Dimensionality reduction identified synergies explaining 98% of movement variance. These synergies enabled accurate reconstruction (95.7% accuracy) of gestures using convex optimization, which were then mirrored by the humanoid robot Mitra. The findings highlight the effectiveness of synergy-based control for natural, efficient human-robot interaction and potential applications in rehabilitation and prosthetics.
    </p>

<!-- Button Group -->
<div class="btn-links" style="margin-top: 1rem; font-size:1em;">
  <button onclick="openBibModal('/assets/bib/Olikkal2024Biomimetic.bib', 'bibModal-biomimetic2024')" 
          class="btn btn-outline-primary btn-page-header btn-sm">Cite</button>
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://doi.org/10.3389/fnhum.2024.1391531" target="_blank" rel="noopener">DOI</a>
</div>

<!-- Modal -->
<div id="bibModal-biomimetic2024" style="display:none; position: fixed; z-index: 9999; left: 0; top: 0; width: 100%; height: 100%;
     background-color: rgba(0,0,0,0.5); text-align: center;">
  <div style="background: #fff; margin: 10% auto; padding: 20px; border-radius: 10px; width: 90%; max-width: 700px; position: relative;">
    <h3>BibTeX Citation</h3>
    <textarea id="bibtexText-biomimetic2024" readonly style="width: 100%; height: 300px; padding: 10px; font-family: monospace;
              border: 1px solid #ccc; border-radius: 6px; color: black; background-color: white">Loading...</textarea>
    <div style="margin-top: 1rem;">
      <button onclick="copyBibTex('bibtexText-biomimetic2024')" class="btn btn-sm" style="margin-right: 10px;">üìã Copy</button>
      <a href="/assets/bib/Olikkal2024Biomimetic.bib" download class="btn btn-sm" style="margin-right: 10px;">‚¨áÔ∏è Download</a>
      <button onclick="document.getElementById('bibModal-biomimetic2024').style.display='none'" class="btn btn-sm">‚ùå Close</button>
    </div>
  </div>
</div>

  </div>
</div>

---

<h2 id="projects">Projects</h2> 

## Humanoid Control using RGB camera

<div style="display: flex; flex-wrap: wrap; gap: 2rem; align-items: flex-start; margin-bottom: 2rem;
            border: 1px solid #e0e0e0; border-radius: 8px; padding: 1.5rem; background: #fafafa; font-size: 0.9em;
            transition: transform 0.2s ease-in-out; box-shadow: 0 0 0 transparent;"
     onmouseover="this.style.transform='scale(1.015)'; this.style.boxShadow='0 8px 20px rgba(0,0,0,0.1)'"
     onmouseout="this.style.transform='scale(1)'; this.style.boxShadow='0 0 0 transparent'">


  <!-- LEFT: Video -->
  <div style="flex: 1 1 350px; min-width: 300px;">
    <img src="/assets/video/Mitra_Mirroring.gif" alt="Gesture Control Demo" style="width: 100%; border-radius: 8px;">
  </div>

  <!-- RIGHT: Text -->
  <div style="flex: 2 1 400px; min-width: 250px; font-size: 0.9em;">
    <p>
      This project demonstrates real-time synergy-based control of a humanoid robot (Mitra) using reconstructed hand gestures.
      Using a single RGB camera and the MediaPipe framework, 33 static hand gestures were captured and processed into joint angular velocities.
      Dimensionality reduction techniques helped extract key kinematic synergies, which were used to reconstruct hand postures with 95.7% accuracy.
    </p>
    <p>
      The resulting synergy-driven control commands were mapped to Mitra‚Äôs actuators in real time, showing promise for intuitive human-robot collaboration in rehabilitation and assistive robotics.
    </p>

  </div>

</div>

<script>
function openBibModal(bibURL, modalID) {
  const modal = document.getElementById(modalID);
  const textarea = modal.querySelector("textarea");

  fetch(bibURL)
    .then(response => response.text())
    .then(data => {
      textarea.value = data;
      modal.style.display = 'block';
    })
    .catch(() => {
      textarea.value = "Failed to load BibTeX.";
      modal.style.display = 'block';
    });
}

function copyBibTex(textareaID) {
  const text = document.getElementById(textareaID);
  text.select();
  document.execCommand("copy");
  alert("BibTeX copied to clipboard!");
}
</script>
